# 提示词效果对比功能说明

## 📌 功能概述

新增的**提示词效果对比**功能允许用户同时对比两个不同版本的系统提示词的实际效果，帮助快速评估提示词优化的成果。

## 🎯 核心特性

### 1. 并排对比
- 左右分屏显示"优化前"和"优化后"两个版本
- 独立配置每个版本的Prompt和模型参数
- 实时并排展示AI响应结果

### 2. 智能变量合并
- 自动合并两个Prompt的变量需求
- 处理变量名冲突（自动重命名为 `_left` 和 `_right` 后缀）
- 统一的变量输入表单，一次配置应用到两侧

### 3. 独立模型配置
- 每侧可配置不同的模型名称
- 独立的Temperature参数控制
- 支持对比不同模型的表现

### 4. 多轮对话支持
- 维护独立的聊天历史
- 相同的用户输入，分别获取两侧响应
- 支持连续对话测试

### 5. 流式输出
- 实时显示AI响应内容
- 提升用户体验
- 降低等待感知时间

## 🚀 使用指南

### 步骤1：选择对比的Prompt

在顶部配置区：
- **左侧（优化前）**：选择原始版本的Prompt
- **右侧（优化后）**：选择优化后的Prompt

每个Prompt都可以展开"模型设置"配置：
- 模型名称（如 `gpt-3.5-turbo`, `gpt-4`）
- Temperature（0.0 - 2.0）

### 步骤2：配置变量

展开"变量配置"区域：
- 系统会自动合并两个Prompt的所有变量
- 如果变量名冲突但类型不同，会显示警告并自动处理
- 填写所有必填变量（标记有 `*`）
- 点击"更新变量"按钮渲染系统提示词

### 步骤3：开始对比测试

在底部输入框输入测试消息：
- 消息会同时发送给左右两侧的LLM
- 实时查看两个版本的响应差异
- 支持多轮对话持续测试

### 步骤4：分析对比结果

观察以下方面的差异：
- **响应质量**：哪个版本的回答更准确、更有用？
- **响应风格**：语气、格式、详细程度
- **指令遵循**：是否正确理解并执行了系统提示词的要求
- **一致性**：多轮对话中的表现稳定性

### 步骤5：重置对话（可选）

点击"重置对话"按钮可清空两侧的聊天历史，开始新的测试场景。

## 💡 使用技巧

### 对比场景示例

#### 场景1：指令清晰度优化
- **优化前**：模糊的指令（如 "帮助用户解决问题"）
- **优化后**：具体的指令（如 "以友好的语气，用3-5句话回答用户的技术问题，必要时提供代码示例"）
- **对比重点**：响应的结构化程度、详细程度

#### 场景2：角色设定优化
- **优化前**：无角色设定
- **优化后**：明确的角色（如 "你是一位经验丰富的Python导师"）
- **对比重点**：回答的专业性、教学风格

#### 场景3：输出格式优化
- **优化前**：无格式要求
- **优化后**：指定Markdown格式、代码块、列表等
- **对比重点**：输出的可读性、格式一致性

### 变量冲突处理

当两个Prompt有相同名称但不同类型的变量时：

```
原始变量: context (type: string)
左侧Prompt: context (type: string) → context_left
右侧Prompt: context (type: array)  → context_right
```

系统会自动重命名为 `context_left` 和 `context_right`，你可以分别配置它们。

### 最佳实践

1. **保持变量一致**：尽量让两个版本使用相同的变量名和类型
2. **逐步优化**：每次只改变一个方面，方便识别改进点
3. **多样化测试**：使用不同类型的输入测试边界情况
4. **记录结果**：观察到明显差异时，记录下来用于决策

## 🔧 技术实现

### 变量合并算法

```python
def merge_variables_meta(left_meta, right_meta):
    """
    合并策略：
    1. 变量名不冲突 → 直接合并
    2. 变量名相同且类型相同 → 保留一个
    3. 变量名相同但类型不同 → 重命名为 _left 和 _right
    """
```

### 消息构建

每次对话时，系统会构建包含完整上下文的消息列表：

```python
messages = [
    SystemMessage(content=rendered_prompt),  # 渲染后的系统提示词
    HumanMessage(content="第1轮用户输入"),
    AIMessage(content="第1轮AI响应"),
    HumanMessage(content="第2轮用户输入"),
    AIMessage(content="第2轮AI响应"),
    # ... 更多历史消息
]
```

### 流式输出

使用 LangChain 的 stream 方法实现：

```python
client = LangChainClient(model_name, temperature)
stream = client.stream(messages)
response = st.write_stream(stream)  # Streamlit实时渲染
```

## 📁 文件说明

- **页面文件**：`pages/04_Prompt_Comparison.py`
- **服务依赖**：
  - `app.services.prompt_service.PromptService` - Prompt数据管理
  - `app.services.template_engine.PromptRenderService` - Jinja2渲染
  - `app.llm.langchain_client.LangChainClient` - LLM调用

## 🐛 已知限制

1. **LLM调用顺序**：当前实现是顺序调用（先左后右），而非真正的并行
   - 原因：Streamlit的流式输出机制限制
   - 影响：右侧响应会稍晚开始显示
   - 未来改进：可使用异步调用优化

2. **变量类型冲突**：需要手动填写两个重命名后的变量
   - 优化方向：可添加"智能映射"功能，自动转换类型

3. **历史记录持久化**：对话历史仅保存在session state中
   - 页面刷新后会丢失
   - 未来改进：可添加导出/保存功能

## 🔮 未来扩展方向

### Phase 6: 高级功能（计划中）

1. **对比结果导出**
   - 导出为Markdown格式
   - 导出为JSON格式
   - 包含Prompt信息、变量、对话历史

2. **差异高亮**
   - 使用 difflib 计算响应差异
   - 在UI中高亮显示不同部分
   - 提供"并排对比"和"统一对比"视图

3. **对比记录保存**（需数据库扩展）
   - 创建 `ComparisonSession` 数据模型
   - 保存对比配置和结果
   - 实现历史对比记录查看

4. **批量测试**
   - 上传测试用例集
   - 自动对比多组输入
   - 生成对比报告

5. **评分系统**
   - 人工评分界面
   - 记录每次对比的优劣判断
   - 统计优化效果

6. **多版本对比**
   - 支持同时对比3个或更多版本
   - 网格布局显示
   - 更复杂的变量合并策略

## 📞 反馈与支持

如遇到问题或有改进建议，请联系开发团队。

---

**创建日期**: 2025-11-20
**版本**: 1.0.0
**状态**: ✅ 已实现并测试
